@article{Come2015,
author = {Etienne CÃ´me and Pierre Latouche},
title ={Model selection and clustering in stochastic block models based on the exact integrated complete data likelihood},
journal = {Statistical Modelling},
volume = {15},
number = {6},
pages = {564-589},
year = {2015},
doi = {10.1177/1471082X15577017},

URL = { 
        https://doi.org/10.1177/1471082X15577017
    
},
eprint = { 
        https://doi.org/10.1177/1471082X15577017
    
}
,
    abstract = { The stochastic block model (SBM) is a mixture model for the clustering of nodes in networks. The SBM has now been employed for more than a decade to analyze very different types of networks in many scientific fields, including biology and the social sciences. Recently, an analytical expression based on the collapsing of the SBM parameters has been proposed, in combination with a sampling procedure that allows the clustering of the vertices and the estimation of the number of clusters to be performed simultaneously. Although the corresponding algorithm can technically accommodate up to 10 000 nodes and millions of edges, the Markov chain, however, tends to exhibit poor mixing properties, that is, low acceptance rates, for large networks. Therefore, the number of clusters tends to be highly overestimated, even for a very large number of samples. In this article, we rely on a similar expression, which we call the integrated complete data log likelihood, and propose a greedy inference algorithm that focuses on maximizing this exact quantity. This algorithm incurs a smaller computational cost than existing inference techniques for the SBM and can be employed to analyze large networks (several tens of thousands of nodes and millions of edges) with no convergence problems. Using toy datasets, the algorithm exhibits improvements over existing strategies, both in terms of clustering and model selection. An application to a network of blogs related to illustrations and comics is also provided. }
}

@article{Newman2016,
  title = {Estimating the Number of Communities in a Network},
  author = {Newman, M. E. J. and Reinert, Gesine},
  journal = {Phys. Rev. Lett.},
  volume = {117},
  issue = {7},
  pages = {078301},
  numpages = {5},
  year = {2016},
  month = {Aug},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.117.078301},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.117.078301}
}

@article{Peixoto2017,
  title = {Nonparametric Bayesian inference of the microcanonical stochastic block model},
  author = {Peixoto, Tiago P.},
  journal = {Phys. Rev. E},
  volume = {95},
  issue = {1},
  pages = {012317},
  numpages = {21},
  year = {2017},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.95.012317},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.95.012317}
}


@Article{Zreik2017,
author="Zreik, Rawya
and Latouche, Pierre
and Bouveyron, Charles",
title="The dynamic random subgraph model for the clustering of evolving networks",
journal="Computational Statistics",
year="2017",
month="Jun",
day="01",
volume="32",
number="2",
pages="501--533",
abstract="In recent years, many clustering methods have been proposed to extract information from networks. The principle is to look for groups of vertices with homogenous connection profiles. Most of these techniques are suitable for static networks, that is to say, not taking into account the temporal dimension. This work is motivated by the need of analyzing evolving networks where a decomposition of the networks into subgraphs is given. Therefore, in this paper, we consider the random subgraph model (RSM) which was proposed recently to model networks through latent clusters built within known partitions. Using a state space model to characterize the cluster proportions, RSM is then extended in order to deal with dynamic networks. We call the latter the dynamic random subgraph model (dRSM). A variational expectation maximization (VEM) algorithm is proposed to perform inference. We show that the variational approximations lead to an update step which involves a new state space model from which the parameters along with the hidden states can be estimated using the standard Kalman filter and Rauch--Tung--Striebel smoother. Simulated data sets are considered to assess the proposed methodology. Finally, dRSM along with the corresponding VEM algorithm are applied to an original maritime network built from printed Lloyd's voyage records.",
issn="1613-9658",
doi="10.1007/s00180-016-0655-5",
url="https://doi.org/10.1007/s00180-016-0655-5"
}


@Article{Bertoletti2015,
author="Bertoletti, Marco
and Friel, Nial
and Rastelli, Riccardo",
title="Choosing the number of clusters in a finite mixture model using an exact integrated completed likelihood criterion",
journal="METRON",
year="2015",
month="Aug",
day="01",
volume="73",
number="2",
pages="177--199",
abstract="The integrated completed likelihood (ICL) criterion has proven to be a very popular approach in model-based clustering through automatically choosing the number of clusters in a mixture model. This approach effectively maximises the complete data likelihood, thereby including the allocation of observations to clusters in the model selection criterion. However for practical implementation one needs to introduce an approximation in order to estimate the ICL. Our contribution here is to illustrate that through the use of conjugate priors one can derive an exact expression for ICL and so avoiding any approximation. Moreover, we illustrate how one can find both the number of clusters and the best allocation of observations in one algorithmic framework. The performance of our algorithm is presented on several simulated and real examples.",
issn="2281-695X",
doi="10.1007/s40300-015-0064-5",
url="https://doi.org/10.1007/s40300-015-0064-5"
}

@article{Corneli2016,
title = "Exact ICL maximization in a non-stationary temporal extension of the stochastic block model for dynamic networks",
journal = "Neurocomputing",
volume = "192",
pages = "81 - 91",
year = "2016",
note = "Advances in artificial neural networks, machine learning and computational intelligence",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2016.02.031",
url = "http://www.sciencedirect.com/science/article/pii/S0925231216002599",
author = "Marco Corneli and Pierre Latouche and Fabrice Rossi",
keywords = "Dynamic networks, Stochastic block models, Exact ICL",
abstract = "The stochastic block model (SBM) is a flexible probabilistic tool that can be used to model interactions between clusters of nodes in a network. However, it does not account for interactions of time varying intensity between clusters. The extension of the SBM developed in this paper addresses this shortcoming through a temporal partition: assuming that interactions between nodes are recorded on fixed-length time intervals, the inference procedure associated with the model we propose allows us to cluster simultaneously the nodes of the network and the time intervals. The number of clusters of nodes and of time intervals, as well as the memberships to clusters, are obtained by maximizing an exact integrated complete-data likelihood, relying on a greedy search approach. Experiments on simulated and real data are carried out in order to assess the proposed methodology."
}

@Article{Rastelli2018,
author="Rastelli, Riccardo
and Friel, Nial",
title="Optimal Bayesian estimators for latent variable cluster models",
journal="Statistics and Computing",
year="2018",
month="Nov",
day="01",
volume="28",
number="6",
pages="1169--1186",
abstract="In cluster analysis interest lies in probabilistically capturing partitions of individuals, items or observations into groups, such that those belonging to the same group share similar attributes or relational profiles. Bayesian posterior samples for the latent allocation variables can be effectively obtained in a wide range of clustering models, including finite mixtures, infinite mixtures, hidden Markov models and block models for networks. However, due to the categorical nature of the clustering variables and the lack of scalable algorithms, summary tools that can interpret such samples are not available. We adopt a Bayesian decision theoretical approach to define an optimality criterion for clusterings and propose a fast and context-independent greedy algorithm to find the best allocations. One important facet of our approach is that the optimal number of groups is automatically selected, thereby solving the clustering and the model-choice problems at the same time. We consider several loss functions to compare partitions and show that our approach can accommodate a wide range of cases. Finally, we illustrate our approach on both artificial and real datasets for three different clustering models: Gaussian mixtures, stochastic block models and latent block models for networks.",
issn="1573-1375",
doi="10.1007/s11222-017-9786-y",
url="https://doi.org/10.1007/s11222-017-9786-y"
}


@ARTICLE{Celeux2018,
       author = {{Celeux}, Gilles and {Fruewirth-Schnatter}, Sylvia and
         {Robert}, Christian P.},
        title = "{Model Selection for Mixture Models - Perspectives and Strategies}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Methodology, Statistics - Computation},
         year = "2018",
        month = "Dec",
          eid = {arXiv:1812.09885},
        pages = {arXiv:1812.09885},
archivePrefix = {arXiv},
       eprint = {1812.09885},
 primaryClass = {stat.ME},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv181209885C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{Fraley2002,
author = {Chris Fraley and Adrian E Raftery},
title = {Model-Based Clustering, Discriminant Analysis, and Density Estimation},
journal = {Journal of the American Statistical Association},
volume = {97},
number = {458},
pages = {611-631},
year  = {2002},
publisher = {Taylor & Francis},
doi = {10.1198/016214502760047131},
}


article{Jordan1999,
 author = {Jordan, Michael I. and Ghahramani, Zoubin and Jaakkola, Tommi S. and Saul, Lawrence K.},
 title = {An Introduction to Variational Methods for Graphical Models},
 journal = {Mach. Learn.},
 issue_date = {Nov.1.1999},
 volume = {37},
 number = {2},
 month = nov,
 year = {1999},
 issn = {0885-6125},
 pages = {183--233},
 numpages = {51},
 url = {https://doi.org/10.1023/A:1007665907178},
 doi = {10.1023/A:1007665907178},
 acmid = {339252},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Bayesian networks, Boltzmann machines, approximate inference, belief networks, graphical models, hidden Markov models, mean field methods, neural networks, probabilistic inference, variational methods},
} 

@article{Baudry2010,
  title={Combining Mixture Components for Clustering.},
  author={Jean-Patrick Baudry and Adrian E. Raftery and Gilles Celeux and Kenneth Lo and Rapha{\"e}l Gottardo},
  journal={Journal of computational and graphical statistics : a joint publication of American Statistical Association, Institute of Mathematical Statistics, Interface Foundation of North America},
  year={2010},
  volume={9 2},
  pages={332-353}
  }
  
  @article{Dempster77,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2984875},
 abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
 author = {A. P. Dempster and N. M. Laird and D. B. Rubin},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {1},
 pages = {1--38},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Maximum Likelihood from Incomplete Data via the EM Algorithm},
 volume = {39},
 year = {1977}
}

@ARTICLE{Celeux92,
title = {A classification EM algorithm for clustering and two stochastic versions},
author = {Celeux, Gilles and Govaert, Gerard},
year = {1992},
journal = {Computational Statistics & Data Analysis},
volume = {14},
number = {3},
pages = {315-332},
url = {https://EconPapers.repec.org/RePEc:eee:csdana:v:14:y:1992:i:3:p:315-332}
}




