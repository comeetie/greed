---
title: "Graph clustering with the Stochastic block model"
author: "Etienne Côme & Nicolas Jouvin"
# date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    number_sections: true
    toc: yes
fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Graph clustering with the Stochastic block model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup-knitr, include = FALSE, message=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


Loads packages and set a future plan for parallel processing.
```{r setup-packages,message=FALSE, include=TRUE}
library(future)
library(Matrix)
library(ggplot2)
library(greed)
library(dplyr)
library(ggpubr)

future::plan("multisession", workers=2) # increase this value to take full advantage of a multi-core machine
```


```{r ggplot-theme, include=FALSE, echo=FALSE, message=FALSE}
# set ggplot2's theme options globally
# th = theme_classic(base_size = 14) +
#   ggplot2::theme(
#       # L'ensemble de la figure
#       plot.title = element_text(size = rel(1), face = "bold", margin = margin(0,0,5,0), hjust = 0),
#       # Zone où se situe le graphique
#       # panel.grid.minor = element_blank(),
#       # panel.border = element_blank(),
#       # Les axes
#       axis.title = element_text(size = rel(0.7), face = "bold"),
#       axis.text = element_text(size = rel(0.55), face = "bold"),
#       axis.line=element_blank(),
#       # La légende
#       legend.title = element_text(size = rel(0.6), face = "bold"),
#       legend.text = element_text(size = rel(0.6), face = "bold"),
#       legend.key = element_rect(fill = "transparent", colour = NA),
#       legend.key.size = unit(1.5, "lines"),
#       legend.background = element_rect(fill = "transparent", colour = NA)
#       )
# ggplot2::theme_set(th)
```

# The model

Graph data arise in various scientific fields from biology to sociology, and accounts for relationship between objects. These objects are expressed as _nodes_, while a relationship between two objects is expressed as an _edge_. Hence, graph data may be expressed and stored in an _adjacency matrix_ $\mathbf{X} = \{ x_{ij} \}$ where $x_{ij}=1$ means that objects $i$ and $j$ are connected. Weighted versions are also possible.  

```{r example-plot-graph, echo=FALSE}
# g <- rsbm(N=15, pi = c(.5, .5), mu=matrix(c(0.9,0.1, 0.1, 0.8),2,2))
# igraph::plot.igraph(graph_from_adjacency_matrix(g$x, mode='undirected'), mark.col = g$cl, mark.shape = g$cl)
```


The stochastic block model (SBM) is a random graph model of the adjacency matrix $\mathbf{X}$ widely used for graph clustering. In this model, the probability of an edge $(i,j)$ is driven by the cluster membership of node $i$ and $j$, hence the __block__ terminology. 

It can be expressed in the [DLVMs](https://arxiv.org/abs/2002.11577) framework and the **greed** package handles this model and its degree-corrected variant, while implementing efficient visualization tools for the clustering results that we detail below. The Bayesian formulation of a binary SBM is as follows

```{=tex}
\begin{equation}
\label{eq:sbm}
\begin{aligned}
\pi&\sim \textrm{Dirichlet}_K(\alpha),\\
\theta_{k,l} & \sim \textrm{Beta}(a_0, b_0), \\
Z_i&\sim \mathcal{M}(1,\pi),\\
\forall (i,j), \quad x_{ij} \mid Z_{ik}Z_{jl}=1& \sim \mathcal{B}(\theta_{k,l}).
\end{aligned}
\end{equation}
```

This model class is implemented in the `?Sbm` class. Here, the model hyperparameters are:

 * $alpha$ which is set to $1$ by default.
 * The beta distribution parameters $a_0$ and $b_0$ on the connectivity matrix $\mathbf{\theta}$. A non-informative prior can be chose with $a_0=b_0=1$, which is the default value in `Sbm`.
 
Note that the greed package also handles the degree-corrected variant of SBM in the `?dcSbm` class, allowing for integer valued edges. The underlying model and its DLVM formulation is described in depth in the Supplementary Materials of [Côme et. al.](https://hal.archives-ouvertes.fr/hal-02530705).
 
# An introductory example: SBM with hierarchical structure


## Simulation scenario
We begin by simulating from a hierarchically structured SBM model, with 2 large clusters, each composed of 3 smaller clusters with higher connection probabilities, making a total of 6 clusters.
```{r, fig.show='hold'}
N=400
K=6
pi=rep(1/K,K)
lambda  = 0.1
lambda_o = 0.01
Ks=3
mu = bdiag(lapply(1:(K/Ks), function(k){
  matrix(lambda_o,Ks,Ks)+diag(rep(lambda,Ks))}))+0.001
sbm = rsbm(N,pi,mu)
```

```{r plot-connectivity-matrix, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5, include=TRUE, echo=FALSE}
df = expand.grid(x=1:K,y=1:K)
df$Theta=c(t(matrix(mu)))
leg_breaks = unique(df$Theta)
gg = ggplot(df, aes(x = x, y = y, fill=Theta, alpha=Theta)) +
  geom_tile() +
  xlab('l') +
  ylab('k') +
  ggplot2::scale_fill_distiller("Theta_{k,l}", breaks = leg_breaks, palette="YlOrRd",direction = 1,guide = ggplot2::guide_legend(),limits=c(0,max(leg_breaks))) +
  ggplot2::scale_alpha("Theta_{k,l}",range=c(0,1),limits=c(0,max(leg_breaks)), breaks = leg_breaks) +
  ggplot2::coord_fixed() + 
  ggplot2::theme_bw() +
  theme(
    panel.background = element_rect(fill = "transparent"), # bg of the panel
    plot.background = element_rect(fill = "transparent", color = NA), # bg of the plot
    panel.grid.major = element_blank(), # get rid of major grid
    panel.grid.minor = element_blank(), # get rid of minor grid
    legend.background = element_rect(fill = "transparent"), # get rid of legend bg
    text = element_text(size=20)
  )
gg
```

<!-- This type of multi-scale clustering structure often arise in and standard greedy algorithm or SBM inference procedures may suffer from local maxima of the ICL  -->


## Clustering with the greed() function


As always, we perform the clustering using the `greed()` function with an `Sbm` model. Note that we need to specify the `Sbm` model, since for squared sparse matrix the default model used is a `DcSbm`. By default, the hybrid genetic algorithm is used, and its default hyperparameters are detailed in ``?`Hybrid-class```.

```{r greed-clustering}
sol = greed(sbm$x,model = Sbm())
```

We see that the fine-grained clustering structure with $K=6$ clusters is recovered.

## Inspecting the clustering results

The result of `greed` is stored as an S4 class and, as for any model, there are dedicated function to access its attributed. A quick summary of these functions is indicated in the display of the `sol` object as follows

```{r display-sol}
sol
```
The `clustering()` function allows to return the estimated partition. The `K()` and `ICL()` functions return the final number of clusters and ICL value respectively.
```
table(sbm$cl,clustering(sol))
```

```{r clustering-method, echo=F, include=TRUE}
knitr::kable(table(sbm$cl,clustering(sol)), format='html')
```



The Maximum a Posteriori (MAP) estimation of $\theta$ and $\pi$ is available through the `coef()` function. Note that the MAP is computed conditionally to the estimated partition returned by `greed`.

```{r get-coef-greed}
coef(sol)
```
## Visualisation tools
The **greed** package also comes with efficient visualization tools for summarization and exploration. For graph data, it allows to:

 1. Plot the aggregated adjacency matrix between the estimated clusters, with colors indicating link density.
 2. Plot a *node-link* diagram representation of the clustering, where each cluster is represented as a point and arrow width indicates link density.
 3. Plot the dendrogram extracted via the hierarchical clustering algorithm from `K(sol)` to `1` with the required level of regularization $\log(\alpha)$. 
 
Note that, in each case, the ordering of the clusters given by the hierarchical algorithm is used and greatly enhances the visualization by highlighting the hierarchical structure in the data.

### Block representation of the adjacency matrix

```{r, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5}
plot(sol,type='blocks')
```



### Node link diagram of the clustering result
```{r, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5}
plot(sol,type='nodelink')
```

### Dendrogram representation of the hierarchical clustering
```{r, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5}
plot(sol,type='tree')
```

## Exploring the hierarchy
Eventually, we can `cut` the dendrogram at any level below `K(sol)` to easily access other partitions in the hierarchy. Here, we access the coarser at $K=2$ and we can still use the different `plot()` functions to visualize these other solutions.

```{r cut-K2, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5}
sol2 = cut(sol,2)
plot(sol2,type='blocks')
```

### Choosing the cut level

Choosing relevant level(s) to `cut` the dendrogram may be challenging and the **greed** package also provides graphical tools to help the user decide based on a chosen heuristics.

 * One can search for changepoints in the evolution of $-log(\alpha)$ with respect to $K$ with the following plot
```{r, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5}
plot(sol,type='path')
```

 * Or of the ICL value with respect to $log(\alpha)$
```{r, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5}
plot(sol,type='front')
```


## Degree corrected variant

Here, we compare models with and without degree correction on DcSbm simulation (see `?rdcsbm`).

```{r dcsbm}
sim_dcsbm <- rdcsbm(N,pi,mu,round(rexp(N,1/15)),round(rexp(N,1/15)))
X <- sim_dcsbm$x
X[X>1] <- 1
sol_dcsbm <- greed(X,model = DcSbm())
sol_dcsbm
sol_sbm <- greed(X,model = Sbm())
sol_sbm
```

As expected the degree corrected version did a better job as the ICL value suggest. Indeed, without degree correction, the model has to use more groups to fit the degree heterogeneity. 

# A (simple) real data example: the Books dataset

The **Books** dataset was gathered by Valdis Krebs and is attached to the **greed** package. It consist of a co-purchasing network of $N=105$ books on US politics. Two books have an edge between them if they have been frequently co-purchased together. We have access to the labels of each book according to its political inclination: conservative ("n"), liberal ("l") or neutral ("n").

```{r}
data(Books)
sol_dcsbm = greed(Books$X,model = DcSbm())
sol_dcsbm
sol_sbm = greed(Books$X,model = Sbm())
sol_sbm
```

The network as been automatically recognized as an undirected graph, as we can see see in the fitted models prior:

```{r}
prior(sol_dcsbm)@type
prior(sol_sbm)@type
```

For this dataset, the regular SBM model seems to reach a better ICL solution than its degree-correction variant. Still, we can visualize both aggregated adjacency matrices and the dendrogram.

```{r, fig.show='hold',out.width="100%",fig.width=8,fig.height=5.5}
bl_sbm = plot(sol_sbm,type='blocks')
bl_dcsbm = plot(sol_dcsbm,type='blocks')
ggarrange(bl_sbm,bl_dcsbm)
```


```{r, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5}
plot(sol_sbm,type='tree')
```

It is also possible to use external R packages to plot the graph layout with node color as clusters and node size as book popularity (computed using centrality degree). Here, we represent the result for the SBM solution with 5 clusters. One can see a hierarchical clustering structure appearing, with a central cluster of neutral books in-between two densily connected set. In each of these two dense set, there is a clear distinction between popular books (heavily purchase) and more peripheric ones, indicated by node size.

```{r, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5, message=FALSE}
library(ggraph)
library(tidygraph)
library(igraph)

graph <- igraph::graph_from_adjacency_matrix(Books$X) %>% as_tbl_graph() %>% 
    mutate(Popularity = centrality_degree())  %>% 
    activate(nodes) %>%
    mutate(cluster=factor(clustering(sol_sbm),1:K(sol_sbm)))

# plot using ggraph
ggraph(graph, layout = 'kk') + 
    geom_edge_link() + 
    geom_node_point(aes(size = Popularity,color=cluster))

```
Finally, we can look at both models solutions for $K=3$. We see that both partition make sense according to the available political label liberals books where correctly recovered 

```{r, echo=FALSE, include=TRUE}
# Regular SBM
sol_sbm_k3 = cut(sol_sbm,3)
knitr::kable(table(clustering(sol_sbm_k3), Books$label), format='html', caption = "Regular SBM")
# DcSbm
knitr::kable(table(clustering(sol_dcsbm), Books$label), format='html', caption = "DC-SBM")
```

# Categorical edges and multiplex graphs

Sometimes, a graph accounts for more complex interactions between object such as
 1. categorical relationship instead of solely binary
 2. multimodal/multilayered relationships encoded by different graphs (*e.g.* work relation and friendship)

The first case can be adressed in the SBM framework via a multinomial SBM model. The second is different since there are different layer or *views* of the data. Still, the **greed** package may handle this type of data via its `MixedModels` framework where user simply stacks the DLVM of its choice on each view of the data (for more info see the dedicated vignette on Mixed Models).

## Multinomial SBM: newguinea dataset
The SBM framework allows virtually any distribution on the edges, hence allowing to handle categorical edges modeled as multinomial random variables. With the right choice of priors, this model admits an exact ICL formulation which allows to use the **greed** framework. This model is implemented in the `MultSbm` S4 class and we illustrate its use on a toy data set consisting in interactions between $n=16$ tribes. This interaction can be one of 3 types: ennemies, friends, no relation. These are encoded as 3 dimensional one-hot vectors in the `NewGuinea` dataset. 

```{r}
data("NewGuinea")
dim(NewGuinea)
```

```{r}
sol_newguinea = greed(NewGuinea,model=MultSbm())
```

```{r, fig.show='hold',out.width="100%",fig.width=8,fig.height=5.5}
plot(sol_newguinea,type='blocks')
```

We can visualize
```{r, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5}

enemies = as.data.frame(which(NewGuinea[,,1]==1,arr.ind = TRUE)) %>% 
  mutate(relation="enemy")
friends = as.data.frame(which(NewGuinea[,,2]==1,arr.ind = TRUE)) %>%
  mutate(relation="friend")

edges = rbind(enemies,friends)
graph = tbl_graph(edges=edges,nodes=data.frame(id=1:16,cluster=factor(clustering(sol_newguinea))))                          
                          
# plot using ggraph
ggraph(graph, layout = 'kk', weights = if_else(relation=="friends",1,0)) + 
    geom_edge_link(aes(color=relation),width=1.2) + 
    scale_edge_color_manual(values = c("friend"="#229922","enemy"="#992222"))+
    geom_node_point(aes(shape=cluster),size=5)

```



```{r}
mod <- MixedModels(list(pos = DcSbmPrior(), neg = DcSbmPrior()))
data <- list(pos = NewGuinea[, , 2], neg = NewGuinea[, , 1])
sol_bidcsbm <- greed(data, model = mod, K = 5)
```

```{r, fig.show='hold',out.width="100%",fig.width=8,fig.height=5.5}
bl_pos = plot(extractSubModel(sol_bidcsbm,"pos"),type="blocks")
bl_neg = plot(extractSubModel(sol_bidcsbm,"neg"),type="blocks")
ggarrange(bl_pos,bl_neg)
```


#### 7th grade dataset


```{r}
data("SevenGraders")
dim(SevenGraders)
```

```{r}
mod <- MixedModels(list(class = DcSbmPrior(), friends = DcSbmPrior(), work = DcSbmPrior()))
data <- list(class = SevenGraders[, , 1], friends = SevenGraders[, , 2], work = SevenGraders[, , 3])
sol <- greed(data, model = mod, K = 5)
```

```{r, fig.show='hold',out.width="70%",fig.width=8,fig.height=5.5}
plot(extractSubModel(sol, "work"), type = "blocks")
```

# Bi-partite graphs and co-clustering


